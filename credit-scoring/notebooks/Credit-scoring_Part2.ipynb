{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d006cd6b",
   "metadata": {},
   "source": [
    "# Apprentissage supervisé avec Python - Credit Scoring"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "173317a9",
   "metadata": {},
   "source": [
    "## II. Apprentissage supervisé : Données hétérogènes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "938a5d12",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "np.set_printoptions(threshold=10000,suppress=True) \n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "68cb5cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier,BaggingClassifier,AdaBoostClassifier,ExtraTreesClassifier\n",
    "from sklearn.model_selection import KFold,cross_val_score,cross_validate\n",
    "from sklearn.tree import DecisionTreeClassifier,plot_tree\n",
    "from sklearn.metrics import confusion_matrix,accuracy_score,precision_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.decomposition import PCA\n",
    "import time"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60e621a8",
   "metadata": {},
   "source": [
    "### Question 1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca7ccb6c",
   "metadata": {},
   "source": [
    "### Chargement des données et préparation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8e441e5",
   "metadata": {},
   "source": [
    "- Importation du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6d7b1499",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('./credit.data', sep='\\t')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2bf8d449",
   "metadata": {},
   "source": [
    "- Création de sous-ensemble des variables numériques"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "84088dc9",
   "metadata": {},
   "source": [
    "Pour cela, nous allons séparer les colonnes numériques des colonnes catégorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f8e7af37",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_num = [1, 2, 7, 10, 13, 14]  # Colonnes numériques\n",
    "col_str = [0, 3, 4, 5, 6, 8, 9, 11, 12]  # Colonnes catégoriques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "cfe718a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 3, 4, 5, 6, 8, 9, 11, 12, 1, 2, 7, 10, 13, 14]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_str + col_num"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bef16d25",
   "metadata": {},
   "source": [
    "Nous allons maintenant remplacer les \"?\" par NaN dans toutes les colonnes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c4932055",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in col_str + col_num:\n",
    "    data.iloc[:, i] = data.iloc[:, i].apply(lambda x: np.nan if x == '?' else x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83753e82",
   "metadata": {},
   "source": [
    "Ensuite nous allons convertir les colonnes numériques en float, puis convertir le DataFrame en numpy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b9f9451d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.iloc[:, col_num] = data.iloc[:, col_num].astype(float)\n",
    "data_np = data.values  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5c7e303c",
   "metadata": {},
   "source": [
    "- Tranformation du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "b075aaa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=data.iloc[:,col_num]\n",
    "Y=data.iloc[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "ec3bd5ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num = data.iloc[:, col_num].astype(float).values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae76bf6",
   "metadata": {},
   "source": [
    "- Suppression des individus contenant des $\\textbf{NaN}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "28ca6e22",
   "metadata": {},
   "outputs": [],
   "source": [
    "data.dropna(axis=0, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5daabef9",
   "metadata": {},
   "source": [
    "- Analyse des propriétés des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "af37f030",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Taille de l'échantillon (lignes, colonnes) : (652, 16)\n"
     ]
    }
   ],
   "source": [
    "print(f\"Taille de l'échantillon (lignes, colonnes) : {data.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0286b654",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pourcentage positif 45.25%, Pourcentage négatif 54.75%\n"
     ]
    }
   ],
   "source": [
    "pourcentage_negative=100*np.sum(Y=='-')/len(Y)\n",
    "pourcentage_positive=100*np.sum(Y=='+')/len(Y)\n",
    "print('Pourcentage positif {0:.2f}%, Pourcentage négatif {1:.2f}%'.format(pourcentage_positive,pourcentage_negative))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "998ebdc8",
   "metadata": {},
   "source": [
    "- Binarisation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "de0388a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "Y = encoder.transform(Y)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1b4f29ed",
   "metadata": {},
   "source": [
    "$\\textbf{Comparaison des résultats obtenus à l'aide des différents algorithmes}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d60ae4de",
   "metadata": {},
   "outputs": [],
   "source": [
    "clfs = {\n",
    "    'NB': GaussianNB(),\n",
    "    'RF': RandomForestClassifier(n_estimators=200, random_state=1),\n",
    "    'BAG': BaggingClassifier(base_estimator=DecisionTreeClassifier(random_state=1), n_estimators=200, random_state=1),\n",
    "    'ADA': AdaBoostClassifier(n_estimators=200, random_state=1),\n",
    "    'ET': ExtraTreesClassifier(n_estimators=200, random_state=1),\n",
    "    'KNN': KNeighborsClassifier(n_neighbors=5),\n",
    "    'CART': DecisionTreeClassifier(criterion='gini', random_state=1),\n",
    "    'ID3': DecisionTreeClassifier(criterion='entropy', random_state=1),\n",
    "    'Stumb': DecisionTreeClassifier(criterion='gini', max_depth=1, random_state=1),\n",
    "    'MLP': MLPClassifier(hidden_layer_sizes=(20, 10), random_state=1),\n",
    "    'XGB': XGBClassifier(n_estimators=200, random_state=1)\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "34c49d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fonction d’évaluation des classifieurs\n",
    "def run_classifieurs(X, Y):\n",
    "    kf = KFold(n_splits=10, shuffle=True, random_state=1)\n",
    "    for i in clfs:\n",
    "        clf = clfs[i]\n",
    "        start = time.time()\n",
    "        cv_results = cross_validate(clf, X, Y, cv=kf, scoring=['accuracy', 'precision', 'roc_auc'])\n",
    "        end = time.time()\n",
    "\n",
    "        print(\"Algorithm: {0}\".format(i))\n",
    "        print(\" - Accuracy: {0:.3f} +/- {1:.3f}\".format(np.mean(cv_results['test_accuracy']), np.std(cv_results['test_accuracy'])))\n",
    "        print(\" - AUC: {0:.3f} +/- {1:.3f}\".format(np.mean(cv_results['test_roc_auc']), np.std(cv_results['test_roc_auc'])))\n",
    "        print(\" - Training time: {0:.3f}s\\n\".format(end - start))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "79cee620",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: NB\n",
      " - Accuracy: 0.713 +/- 0.040\n",
      " - AUC: 0.801 +/- 0.025\n",
      " - Training time: 0.389s\n",
      "\n",
      "Algorithm: RF\n",
      " - Accuracy: 0.784 +/- 0.036\n",
      " - AUC: 0.846 +/- 0.043\n",
      " - Training time: 10.747s\n",
      "\n",
      "Algorithm: BAG\n",
      " - Accuracy: 0.768 +/- 0.035\n",
      " - AUC: 0.836 +/- 0.043\n",
      " - Training time: 16.363s\n",
      "\n",
      "Algorithm: ADA\n",
      " - Accuracy: 0.762 +/- 0.030\n",
      " - AUC: 0.820 +/- 0.051\n",
      " - Training time: 9.608s\n",
      "\n",
      "Algorithm: ET\n",
      " - Accuracy: 0.762 +/- 0.025\n",
      " - AUC: 0.839 +/- 0.044\n",
      " - Training time: 8.058s\n",
      "\n",
      "Algorithm: KNN\n",
      " - Accuracy: 0.695 +/- 0.033\n",
      " - AUC: 0.730 +/- 0.038\n",
      " - Training time: 0.412s\n",
      "\n",
      "Algorithm: CART\n",
      " - Accuracy: 0.681 +/- 0.074\n",
      " - AUC: 0.682 +/- 0.076\n",
      " - Training time: 0.292s\n",
      "\n",
      "Algorithm: ID3\n",
      " - Accuracy: 0.732 +/- 0.066\n",
      " - AUC: 0.733 +/- 0.069\n",
      " - Training time: 0.196s\n",
      "\n",
      "Algorithm: Stumb\n",
      " - Accuracy: 0.744 +/- 0.047\n",
      " - AUC: 0.724 +/- 0.045\n",
      " - Training time: 0.171s\n",
      "\n",
      "Algorithm: MLP\n",
      " - Accuracy: 0.639 +/- 0.048\n",
      " - AUC: 0.669 +/- 0.036\n",
      " - Training time: 1.757s\n",
      "\n",
      "Algorithm: XGB\n",
      " - Accuracy: 0.755 +/- 0.042\n",
      " - AUC: 0.835 +/- 0.048\n",
      " - Training time: 2.104s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_classifieurs(X,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "267d616e",
   "metadata": {},
   "source": [
    "Le Random Forest (RF) est le meilleur modèle car il offre un bon équilibre entre précision ($78.4\\%$) et AUC ($84.6\\%$), malgré un temps d'entraînement plus long.\n",
    "\n",
    "Les modèles comme CART, Stump et MLP sont moins efficaces, leurs AUC sont trop faibles\n",
    "\n",
    "Toutefois, Bagging ($83.6\\%$), Extra Trees ($83.9\\%$) et XGBoost ($83.6\\%$) sont de bonnes alternatives"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a9893d1b",
   "metadata": {},
   "source": [
    "### Normalisation des variables continues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "eef4c612",
   "metadata": {},
   "outputs": [],
   "source": [
    "SS=StandardScaler()\n",
    "SS.fit(X)\n",
    "Xnorm=SS.transform(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "8148332e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: NB\n",
      " - Accuracy: 0.713 +/- 0.040\n",
      " - AUC: 0.801 +/- 0.025\n",
      " - Training time: 0.207s\n",
      "\n",
      "Algorithm: RF\n",
      " - Accuracy: 0.784 +/- 0.036\n",
      " - AUC: 0.846 +/- 0.043\n",
      " - Training time: 11.191s\n",
      "\n",
      "Algorithm: BAG\n",
      " - Accuracy: 0.768 +/- 0.035\n",
      " - AUC: 0.837 +/- 0.043\n",
      " - Training time: 13.585s\n",
      "\n",
      "Algorithm: ADA\n",
      " - Accuracy: 0.762 +/- 0.030\n",
      " - AUC: 0.820 +/- 0.051\n",
      " - Training time: 8.829s\n",
      "\n",
      "Algorithm: ET\n",
      " - Accuracy: 0.762 +/- 0.025\n",
      " - AUC: 0.839 +/- 0.044\n",
      " - Training time: 7.527s\n",
      "\n",
      "Algorithm: KNN\n",
      " - Accuracy: 0.748 +/- 0.056\n",
      " - AUC: 0.808 +/- 0.042\n",
      " - Training time: 0.162s\n",
      "\n",
      "Algorithm: CART\n",
      " - Accuracy: 0.684 +/- 0.073\n",
      " - AUC: 0.685 +/- 0.075\n",
      " - Training time: 0.160s\n",
      "\n",
      "Algorithm: ID3\n",
      " - Accuracy: 0.733 +/- 0.065\n",
      " - AUC: 0.734 +/- 0.069\n",
      " - Training time: 0.231s\n",
      "\n",
      "Algorithm: Stumb\n",
      " - Accuracy: 0.744 +/- 0.047\n",
      " - AUC: 0.724 +/- 0.045\n",
      " - Training time: 0.112s\n",
      "\n",
      "Algorithm: MLP\n",
      " - Accuracy: 0.785 +/- 0.054\n",
      " - AUC: 0.844 +/- 0.056\n",
      " - Training time: 6.485s\n",
      "\n",
      "Algorithm: XGB\n",
      " - Accuracy: 0.755 +/- 0.042\n",
      " - AUC: 0.835 +/- 0.048\n",
      " - Training time: 1.575s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_classifieurs(Xnorm,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a334338d",
   "metadata": {},
   "source": [
    "Les modèles KNN et les réseaux de neurones MLP ont vu une nette amélioration de leur performance après normalisation, ils sont sensibles à l’échelle des données.\n",
    "\n",
    "Les modèles basés sur les arbres (Random Forest, XGBoost, Extra Trees, etc.) n'ont pas été impactés par la normalisation.\n",
    "\n",
    "Le meilleur modèle reste Random Forest (RF) avec une AUC de $0.846$, suivi de MLP ($0.844$) et Extra Trees ($0.839$)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83f1327e",
   "metadata": {},
   "source": [
    "### Question 2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "203118d0",
   "metadata": {},
   "source": [
    "### Traitement des données manquantes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "36253d52",
   "metadata": {},
   "outputs": [],
   "source": [
    "credit = pd.read_csv('credit.data', sep='\\t',header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "81eb95ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "X=credit.iloc[:,:-1].values\n",
    "Y=credit.iloc[:,-1].values\n",
    "col_num = [1,2, 7, 10, 13,14]\n",
    "col_cat = [0,3,4,5,6,8,9,11,12]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "152697ca",
   "metadata": {},
   "source": [
    "Pour les variables catégorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "aadc325f",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_cat = np.copy(X[:, col_cat])\n",
    "for col_id in range(len(col_cat)):\n",
    "    unique_val, val_idx = np.unique(X_cat[:, col_id], return_inverse=True)\n",
    "    X_cat[:, col_id] = val_idx\n",
    "    \n",
    "imp_cat = SimpleImputer(missing_values=0, strategy='most_frequent')\n",
    "X_cat[:, range(5)] = imp_cat.fit_transform(X_cat[:, range(5)])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "15ac635f",
   "metadata": {},
   "source": [
    "Pour les variables numériques"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "c2d5789a",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_num = np.copy(X[:, col_num])\n",
    "X_num[X_num == '?'] = np.nan\n",
    "X_num = X_num.astype(float)\n",
    "imp_num = SimpleImputer(missing_values=np.nan, strategy='mean')\n",
    "X_num = imp_num.fit_transform(X_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "3d56c50e",
   "metadata": {},
   "outputs": [],
   "source": [
    "encoder = LabelEncoder()\n",
    "encoder.fit(Y)\n",
    "Y = encoder.transform(Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6a5eab81",
   "metadata": {},
   "source": [
    "### Traitement de varaibles catégorielles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "7dd1e5b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "X_cat_bin = OneHotEncoder().fit_transform(X_cat).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a8e852db",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 1., 0., ..., 1., 0., 0.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 1., 0., ..., 1., 0., 0.],\n",
       "       [0., 1., 0., ..., 1., 0., 0.]])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_cat_bin"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a84910d2",
   "metadata": {},
   "source": [
    "### Construction du jeu de données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c1043daa",
   "metadata": {},
   "outputs": [],
   "source": [
    "Xconc = np.concatenate((X_cat_bin,X_num),axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "2b965d55",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Algorithm: NB\n",
      " - Accuracy: 0.840 +/- 0.046\n",
      " - AUC: 0.910 +/- 0.035\n",
      " - Training time: 0.175s\n",
      "\n",
      "Algorithm: RF\n",
      " - Accuracy: 0.875 +/- 0.040\n",
      " - AUC: 0.931 +/- 0.039\n",
      " - Training time: 9.626s\n",
      "\n",
      "Algorithm: BAG\n",
      " - Accuracy: 0.871 +/- 0.043\n",
      " - AUC: 0.918 +/- 0.048\n",
      " - Training time: 14.870s\n",
      "\n",
      "Algorithm: ADA\n",
      " - Accuracy: 0.830 +/- 0.043\n",
      " - AUC: 0.885 +/- 0.065\n",
      " - Training time: 9.519s\n",
      "\n",
      "Algorithm: ET\n",
      " - Accuracy: 0.865 +/- 0.046\n",
      " - AUC: 0.911 +/- 0.040\n",
      " - Training time: 7.283s\n",
      "\n",
      "Algorithm: KNN\n",
      " - Accuracy: 0.698 +/- 0.056\n",
      " - AUC: 0.730 +/- 0.035\n",
      " - Training time: 2.181s\n",
      "\n",
      "Algorithm: CART\n",
      " - Accuracy: 0.805 +/- 0.041\n",
      " - AUC: 0.800 +/- 0.047\n",
      " - Training time: 0.133s\n",
      "\n",
      "Algorithm: ID3\n",
      " - Accuracy: 0.804 +/- 0.024\n",
      " - AUC: 0.798 +/- 0.025\n",
      " - Training time: 0.154s\n",
      "\n",
      "Algorithm: Stumb\n",
      " - Accuracy: 0.856 +/- 0.032\n",
      " - AUC: 0.861 +/- 0.027\n",
      " - Training time: 0.086s\n",
      "\n",
      "Algorithm: MLP\n",
      " - Accuracy: 0.773 +/- 0.065\n",
      " - AUC: 0.842 +/- 0.055\n",
      " - Training time: 6.634s\n",
      "\n",
      "Algorithm: XGB\n",
      " - Accuracy: 0.871 +/- 0.038\n",
      " - AUC: 0.924 +/- 0.042\n",
      " - Training time: 2.229s\n",
      "\n"
     ]
    }
   ],
   "source": [
    "run_classifieurs(Xconc,Y)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6550b76",
   "metadata": {},
   "source": [
    "Les meilleurs modèles sont Random Forest (AUC = 0.931), XGBoost (0.924), Bagging (0.918), Extra Trees (0.911), Naïve Bayes (0.910) avec une excellente capacité de classification.\n",
    "\n",
    "Les modèles AdaBoost (0.885), MLP (0.842), Stump (0.861) sont aussi performants.\n",
    "\n",
    "Par contre le modèle KNN (0.730) a une faible distinction des classes et temps d’entraînement élevé.\n",
    "\n",
    "Le modèle XGBoost est le meilleur choix si l'on recherche un on équilibre entre performance (0.924) et rapidité (2.2s)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27b36299",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
